# pro_eval

A framework for creating bioinformatics analysis evaluation questions from research papers.

## Structure

- `context/` - Guides and example questions with data, notebooks, answers, and rubrics
- `papers/` - Research papers used as sources for questions
- `tasks/` - Evaluation tasks and questions

## Overview

This project converts research papers into structured computational questions, each with:
- Clean, documented data files
- Jupyter notebooks performing the analysis
- Ground-truth answers
- Scoring rubrics

See `context/paperbench_guide.md` for detailed instructions on creating questions.

